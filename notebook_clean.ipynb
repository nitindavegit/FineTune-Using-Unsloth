{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1JpMU4PlKd-HYCB-BfygE1CnE9naSS9M3",
      "authorship_tag": "ABX9TyNPXGcTxocCIlt02yvnFYvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitindavegit/FineTune-Using-Unsloth/blob/main/notebook_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaGXKgLochXM",
        "outputId": "3b95b07d-93f0-47c2-c80b-10ae8074e8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.7/290.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m832.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip install -q --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! Unsloth also supports RoPE (Rotary Positinal Embedding) scaling internally.\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit, # Will load the 4Bit Quantized Model\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "c983825aebb1401586ff99cb28c3794d",
            "c5d9417751454d1d92b7d3411383e8b9",
            "bc148c9165bf418dbd8559762ce86991",
            "a005a46c948443e48af36be57b78a1d7",
            "50ab0cb3cbb34d8780af42ad9ef0bad8",
            "b7e96bd33d6b4f5aadb425ff958bb23e",
            "40a2730cc1b440f8b44e314e147a17f1",
            "29a2c0af429146f2b4ace536f85cabce",
            "41bf4fce7b8142c9ab32fdae422f4ae9",
            "d1ba24db461342628c78c7890b9ad6b8",
            "19c3ddd71b2c47a1bbd3751bc78f1769",
            "d47f43c94c4c4ba994984581ef5f308e",
            "23650736219746ceb4a5caf975292791",
            "96d55a00f0ea4eb2861308832c4d0583",
            "5d524aa602294251857a82413832e364",
            "84a6e72409394180bac779074bfc0334",
            "7c70fee6083e479a8dfcca3a813b1de2",
            "00eba138655341079d9baf85cfca288a",
            "97746c25c7aa4478805696a8b5ecc5c9",
            "f7b6db09e32f4083b5ec6a2d197d9d37",
            "3617d09b66544477ac7b0d2bed351afc",
            "219d734c1f6c49cfaeafa066a852ad8f",
            "cb52839f12fb4502875342eb29bc2182",
            "da7770b896d94fdf9fe8860dc53ac7bc",
            "f3788730319c43ca83d155afc9d1b0a0",
            "df4ac24a456f48859d2a42acc6cb3e79",
            "5e8460e370be4d999adf0091e86fd1bd",
            "7a209cdfca5f46da8678c9d541b299be",
            "ef29eca00e254c619a4eff2b76f7d27c",
            "65b5680c89ef485ab532924e0e094169",
            "599c1fccb1834d47bf59f567da166740",
            "d4ad4f2475354c82a16ca239f33ab01a",
            "a8274bf416fd4b35b458ebfec5e8c58c",
            "8fed5991132647879091088eb6656c40",
            "08ee90ea45d9457bb138cbed097cc6af",
            "e034e599766241ad8b0a27298004732f",
            "3b8b7c9b34df434981cffc44092ef845",
            "0251c99d975d4474afa334eabc762e9d",
            "5df2e59c403e4ff889865a6e0f5e0095",
            "fa1c8ce912074e4da90442bcbcbecb86",
            "326619f8831d4826b599b1d3569795f8",
            "5eb2d122b9e84601842956c76f80c74a",
            "e7cfc2390f284843bb43222d6e52a3af",
            "0df2bf524736472c959fb2ba75bd2a8b",
            "26a72e3a598c4553be671cdf152d64ee",
            "1fba5aa60e6d4b30a741a596d31ed28d",
            "a12dcf5a18974e44ab435491a325c8dd",
            "aa231e9a282a44d0a5f3036af2f7050f",
            "18917663f9e546abbef39004c6340517",
            "47da895614dc44cf92bbbb314affc3da",
            "810943201a204549aa2b5103c78b468b",
            "6d4bd8bd5bbb48bf8815848056e8a4e9",
            "61a8ddbec39743ef95ee522f4109e728",
            "bc1ba0ee28744835ac7aea58a4cd320a",
            "640cd3bc830e4b5fb718c8f3158a944e",
            "a72932081bad4bcd9b2e58dfceee6bbd",
            "6b41e5fcd20744d48b27b486fe4f34f7",
            "f8b80bfa3d594beea3cde7e30706a4b2",
            "0cc773dd4ff94d8a9458d75de0c4f37c",
            "26d1590944b64968b6d7859a2cef3d4d",
            "3b62571107bb47acb07f12c906f08b26",
            "da7ff372608a4670b1db94b28b8b33a3",
            "11e81e217a55402e836f16240c218008",
            "e93e75581789451b8d6b5d2c364d01cf",
            "923412811b634c6dbe69dd424b252b78",
            "bbf39b085828426881fd2b4513409390"
          ]
        },
        "id": "5QjkD-Noc0fa",
        "outputId": "e2b143fa-6ccd-4e15-cc91-fe385fe30f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c983825aebb1401586ff99cb28c3794d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d47f43c94c4c4ba994984581ef5f308e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb52839f12fb4502875342eb29bc2182"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fed5991132647879091088eb6656c40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26a72e3a598c4553be671cdf152d64ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a72932081bad4bcd9b2e58dfceee6bbd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16, # a higher alpha value assigns more weight to the LoRA activations\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ],
      "metadata": {
        "id": "Oi7UE_mDd3uQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb96d16-4f19-443c-d7f6-b9f5d6d8fd65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.12.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"ServiceNow-AI/R1-Distill-SFT\",'v0', split = \"train\")"
      ],
      "metadata": {
        "id": "uzpoleRVeJbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "3a0fa3b3ec6b46e9ae18a0fe47bd7a30",
            "8d2af82c124a460db63b2c3090342cda",
            "49948e43df884de9a2fa11d6402a9449",
            "5181209ad64d452fa69de9fd83893bb7",
            "81010b5bd3ee4331a563b141dc30d81f",
            "924c31881d354380ae9f142837604e21",
            "98547f1c7b134f17a2bcc635559cff4a",
            "12fe0530fa08432e973ed5e4e6370c09",
            "f8a5623d02414425a1288db9d9add116",
            "de48e3ed65de4f88a9b4fbb288628013",
            "ff8d9a1086f94879bc95764a480e3b7f",
            "fb204ecca846491e9791e17331ad238f",
            "5234074c3e1b4e2eb5aad21225d95c3e",
            "1c2cb1dc9ef84500a37ba309db58617f",
            "69801fe8f1aa4e5ba89e30fdc81b27b6",
            "8e78afa8440040e9905dce995f207dd0",
            "abdd100da1e94bb9a8e5c687e44c8fbf",
            "f2e5669146954f609475a49c36d82099",
            "15b8ddfe7e4f428c8aa58a9fdd131f3c",
            "b0aff38e5de04d908ea88d9d0ab9d940",
            "37bb538be66c4876b5b74c1d30792ae1",
            "9c166e328003407b9df875be277a41a2",
            "fe6478de55e549dab681ecd133e2ab05",
            "81975b29eeae4d688da004cbf1aaaa09",
            "a23713bbf13443fc991df7f925fec235",
            "29f6220cd76e46fd8378850a248fbe62",
            "8952576ca8014f1f83aff8070019064d",
            "586f070829d94f8db7cfc5d6bfc9bacc",
            "62151255e18240809d4ec2a348d0cc0a",
            "aba78bff1e744175ba149b965e9fbef8",
            "4c6767cc00424d31af207dbc975367b2",
            "3edea5aac2ee4493945f3d142f4a8605",
            "9ab2ae60f4cb4dfea7295611ddb9d386",
            "4fc517e81df14811b905c97fce6b236b",
            "8e3b7a5ab29b497389aedf742d4b19ef",
            "6211151bd0364f26aa85bf839193a071",
            "60f3623d098942679c4dd8f0f4f08a1b",
            "c2235ca1ff8f4348bf3a36b98eb1190b",
            "696c64d424c74ed7a17c53d3fde5595b",
            "55b22f8c01c5473db7e35718bb5a7e86",
            "c6afaa15ae984302a4a2eb8d33416ef2",
            "e0f5609cd55548c69f582a3f86bf04fd",
            "e208fee710e94dc19b05697fcf50ec28",
            "4e9934e5028c414b82c3e99c01183491",
            "ab3c99c5fe0b4e2baedb0bba1db61ad1",
            "73128eaf9898457395e32db8f582cd4f",
            "3d59ab68023340e7b545be5a4abb0df5",
            "1c3f12f7d96e4380bee3c0963275c2e6",
            "2c5b09e4fada470087ea5f4ea38d31c4",
            "5c1b84dbb033475090f261d180b4065b",
            "3bf88531002f4f99b2fa9dbba96f8387",
            "af65bf915e64476a8b6251b86eb17328",
            "724316363d254b1e967d3429c878bb5e",
            "0eda35c2e28149cf9da129862da2ce65",
            "01467ad1980a4d6b917cf35e0936f174"
          ]
        },
        "outputId": "2a1433c0-f98f-4795-bed3-53812e0e5a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a0fa3b3ec6b46e9ae18a0fe47bd7a30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "v0/train-00000-of-00003.parquet:   0%|          | 0.00/180M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb204ecca846491e9791e17331ad238f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "v0/train-00001-of-00003.parquet:   0%|          | 0.00/187M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe6478de55e549dab681ecd133e2ab05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "v0/train-00002-of-00003.parquet:   0%|          | 0.00/188M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fc517e81df14811b905c97fce6b236b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/171647 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab3c99c5fe0b4e2baedb0bba1db61ad1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[:2])"
      ],
      "metadata": {
        "id": "mtwr6AnAeMA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d8eebf-d81a-4a31-9d09-d4fd0f244455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': ['id_0', 'id_1'], 'reannotated_assistant_content': ['<think>\\nFirst, I need to determine the total number of children on the playground by adding the number of boys and girls.\\n\\nThere are 27 boys and 35 girls.\\n\\nAdding these together: 27 boys + 35 girls = 62 children.\\n\\nTherefore, the total number of children on the playground is 62.\\n</think>\\n\\nTo find the total number of children on the playground, we simply add the number of boys and girls together.\\n\\n\\\\[\\n\\\\text{Total children} = \\\\text{Number of boys} + \\\\text{Number of girls}\\n\\\\]\\n\\nPlugging in the given values:\\n\\n\\\\[\\n\\\\text{Total children} = 27 \\\\text{ boys} + 35 \\\\text{ girls} = 62 \\\\text{ children}\\n\\\\]\\n\\n**Final Answer:**\\n\\n\\\\[\\n\\\\boxed{62}\\n\\\\]', '<think>\\nFirst, I need to determine the cost per dozen oranges. John bought three dozen oranges for \\\\$28.80, so I can find the cost per dozen by dividing the total cost by the number of dozens.\\n\\nNext, with the cost per dozen known, I can calculate the cost for five dozen oranges by multiplying the cost per dozen by five.\\n\\nFinally, I will present the final answer clearly.\\n</think>\\n\\n**Solution:**\\n\\nTo determine the cost of five dozen oranges at the same rate, follow these steps:\\n\\n1. **Find the cost per dozen:**\\n\\n   John purchased three dozen oranges for \\\\$28.80. To find the cost per dozen, divide the total cost by the number of dozens.\\n\\n   \\\\[\\n   \\\\text{Cost per dozen} = \\\\frac{\\\\$28.80}{3} = \\\\$9.60 \\\\text{ per dozen}\\n   \\\\]\\n\\n2. **Calculate the cost for five dozen:**\\n\\n   Now, multiply the cost per dozen by the number of dozens needed.\\n\\n   \\\\[\\n   \\\\text{Cost for five dozen} = 5 \\\\times \\\\$9.60 = \\\\$48.00\\n   \\\\]\\n\\n3. **Final Answer:**\\n\\n   \\\\[\\n   \\\\boxed{\\\\$48}\\n   \\\\]'], 'problem': ['There were 27 boys and 35 girls on the playground at recess. There were _____ children on the playground at recess.', 'John purchased three dozen oranges for $\\\\$$28.80. At the same rate, how much would five dozen of these oranges cost?'], 'source': ['orca_math', 'synthetic_math'], 'solution': ['\\nThere were 62 children on the playground at recess. (27 boys + 35 girls = $\\\\boxed{62}$  children)', 'The problem states that John bought three dozen oranges for $\\\\$$28.80. To find the cost per dozen, we use the formula:\\n$$ \\\\text{Cost per dozen} = \\\\frac{\\\\text{Total cost}}{\\\\text{Number of dozens}} = \\\\frac{\\\\$28.80}{3} = \\\\$9.60 \\\\text{ per dozen}. $$\\n\\nTo determine the cost for five dozen oranges:\\n$$ \\\\text{Cost for five dozen} = 5 \\\\times \\\\text{Cost per dozen} = 5 \\\\times \\\\$9.60 = \\\\$48. $$\\n\\nThus, the cost for five dozen oranges is $\\\\boxed{\\\\$48}$.'], 'verified': [None, None], 'quality_metrics': [None, None]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1_prompt = \"\"\"You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n",
        "<problem>\n",
        "{}\n",
        "</problem>\n",
        "\n",
        "{}\n",
        "{}\n",
        "\"\"\"\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "  problems = examples[\"problem\"]\n",
        "  thoughts = examples[\"reannotated_assistant_content\"]\n",
        "  solutions = examples[\"solution\"]\n",
        "  texts = []\n",
        "\n",
        "  for problem, thought, solution in zip(problems, thoughts, solutions):\n",
        "    text = r1_prompt.format(problem, thought, solution)+EOS_TOKEN\n",
        "    texts.append(text)\n",
        "\n",
        "  return {\"text\": texts}\n",
        "\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "id": "koUrkomGeQgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2f0930ba27234c5ebc033f6ff74b759b",
            "4b697847752e4f24b17862ae4d1479eb",
            "190c9024e20848b09f7c88f963302a6f",
            "84105df3210c44ea8f6d3421400c46c1",
            "3a1d0679c82d4c8fa17cdf1beb6a3d8b",
            "a82f089d0c5c4fd084a90d22332f6913",
            "eb19ef78c915412b96387dfac4b8e34b",
            "f60da399d67540329ce4e635c9e10a84",
            "5321d38409314da8887e667df0eb9874",
            "91c09249fd864f0b83450c5ccfe28d14",
            "7b1c711d05634a9a8df2ddc826b13f74"
          ]
        },
        "outputId": "fc789c98-ec8c-4953-91a7-5428f87fdc3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/171647 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f0930ba27234c5ebc033f6ff74b759b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2, # Number of processors to use for processing the dataset\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2, # The batch size per GPU/TPU core\n",
        "        gradient_accumulation_steps = 4, # Number of steps to perform befor each gradient accumulation\n",
        "        warmup_steps = 5, # Few updates with low learning rate before actual training\n",
        "        max_steps = 60, # Specifies the total number of training steps (batches) to run.\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\", # Optimizer\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc for observability\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "sWXPTQUdeQ7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f80c123bbfb048f497e004d949fca764",
            "7ae893091837443184b6086c23b48557",
            "867f8848552241baa8592b55b6baebe6",
            "16362b38d8e9467bb452d601e8d6debc",
            "80828caf148448019ff59acb63f14245",
            "a3ca2a9935f0428fb1334b3720fe5fee",
            "21657d54b9224d658af063d232df1aa0",
            "fcd98f3c6f42492f9fa68bdf97fa6e94",
            "3b221b370be6414eb39a59be670460c7",
            "27ef238f66b846f68783cd1f30dc2d37",
            "52841e5c36e54812aa06aa4504e94cba"
          ]
        },
        "outputId": "f4e4587a-c137-4346-8695-2cf003720add"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f80c123bbfb048f497e004d949fca764",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/171647 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "isdW0nYreY22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdf4f65a-ce03-4e05-b8ea-46ee9dc62e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 171,647 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/60 03:27 < 04:53, 0.12 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.935000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.944000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.786000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.853600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.756600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.741700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.786500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.736800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.640200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.637200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.621100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.568000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.633000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.574300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.557600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.522600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.559000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.721500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.626400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 08:42, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.935000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.944000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.786000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.853600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.756600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.741700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.786500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.736800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.640200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.637200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.621100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.568000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.633000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.574300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.557600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.522600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.559000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.721500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.626400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.602600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.607700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.539600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.493500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.589300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.472400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.652200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.601900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.625400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.711600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.530900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.463700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.586300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.594600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.584900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.606300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.592100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.557500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.484900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.552900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.549300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.597200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.539200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.494000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.534500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.503500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.623600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.579500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.702400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.620500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.430200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.617900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.503500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "sys_prompt = \"\"\"You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n",
        "<problem>\n",
        "{}\n",
        "</problem>\n",
        "\"\"\"\n",
        "message = sys_prompt.format(\"How many 'r's are present in 'strawberry'?\")\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": message},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 1024, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "response = tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "0G8SudXBiKDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18255113-efe5-464e-a4d0-ff349b2b4211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"nitin-001-3B\")  # Local saving\n",
        "tokenizer.save_pretrained(\"nitin-001-3B\")"
      ],
      "metadata": {
        "id": "JvmWeZzIlKhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e63752c-169e-453a-d77b-3f557d81fabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('nitin-001-3B/tokenizer_config.json',\n",
              " 'nitin-001-3B/special_tokens_map.json',\n",
              " 'nitin-001-3B/chat_template.jinja',\n",
              " 'nitin-001-3B/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[0])"
      ],
      "metadata": {
        "id": "7AEY0XA3ah8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0045030f-4928-483a-fdc8-1a39160e8662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n",
            "<problem>\n",
            "How many 'r's are present in'strawberry'?\n",
            "</problem>\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Alright, let me figure out how many 'r's are in the word'strawberry'. Okay, so I remember that 'r' is the seventh letter of the alphabet, but is that correct? Let me just check again to make sure. In the standard English alphabet, 'r' is indeed the seventh letter, so that's probably correct.\n",
            "\n",
            "Okay, now, looking at'strawberry'. It's a seven-letter word. I need to count the number of 'r's in it. Let's break it down:\n",
            "\n",
            "- S: That's's'. No 'r's here.\n",
            "- T: That's 't'. Still no 'r'.\n",
            "- R: Hmm, there is a 'r' here. That's the second letter. Okay, so one 'r'.\n",
            "- A: 'a' doesn't have an 'r'. Nope.\n",
            "- W: That's 'w'. Still no 'r'.\n",
            "- B: 'b'. No 'r'.\n",
            "- E: 'e'. Not 'r'.\n",
            "\n",
            "Okay, so up to 'E', there's only one 'r'. Let me continue:\n",
            "\n",
            "- R: Second 'r'. Wait, let's not count twice. Let me see if it repeats. So,'s', 't', 'r', 'a', 'w', 'b', 'e', and then the final 'r' appears in 'berry'. So, it seems like 'r' only appears twice.\n",
            "\n",
            "Let me double-check. From's' to the last 'r' in 'berry', there are indeed'straw' and 'berry'. In'straw', there's one 'r', and in 'berry', there's another. So, one in'straw', another in 'berry'. So, that's two.\n",
            "\n",
            "Yes, I'm pretty sure that's correct. Let me summarize:\n",
            "\n",
            "-'s' to 't': 5 letters, but no 'r'.\n",
            "- 't' to the next 'r': 5 letters, and the first 'r' appears here. That's 2 'r's so far: one from's', 't', and the second from 'r'.\n",
            "- 'r' to the next letters: 4 letters, none 'r'.\n",
            "- Next 'r' in 'berry': That's a different one.\n",
            "\n",
            "So, yes, that makes two. I don't see any other 'r's in'strawberry'. Maybe if I write it out:\n",
            "\n",
            "S-T-R-A-W-B-E-R-R-Y\n",
            "\n",
            "See? Two 'r's in there. So, definitely 2.\n",
            "\n",
            "I think I made sure to check carefully. If I was miscounting or misreading, I would probably get a different number. But no, one 'r' from the first part and another 'r' from 'berry'. That's two total. So, the answer is:\n",
            "\n",
            "2.\n",
            "\n",
            " Wait, I double-checked to make sure. I don't see any other 'r's after the first one. So, yes, that must be right. 2 'r's in the word'strawberry'.\n",
            "\n",
            "Alright, that seems solid. Let me recap:\n",
            "\n",
            "1. Break the word down into individual letters: S, T, R, A, W, B, E, R, R, Y.\n",
            "2. Identify each letter: S is an's', T is a 't', R is an 'r', A is an 'a', W is an 'w', B is a 'b', E is an 'e', and R and R and Y are Rs.\n",
            "3. Count the 'r's: The first 'R' is the 4th letter, so that's one. The second 'R' is the 6th letter, which is the letter before Y. So, there's a second 'R' here.\n",
            "4. Count all Rs: First R (4th) + second R (6th).\n",
            "5. Make sure no Rs in other parts: From's' to 'r' (T), R to E, no other Rs.\n",
            "6. Double-check with writing out the word or using a counter, just to ensure accuracy.\n",
            "\n",
            "Alright, 2 Rs in total. That seems accurate to me.\n",
            "<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "// /content/drive/MyDrive/Colab Notebooks/Unsloth_FineTune.ipynb\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Unsloth_FineTune.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "# Remove widget metadata\n",
        "nb[\"metadata\"].pop(\"widgets\", None)\n",
        "\n",
        "with open(\"content/drive/MyDrive/Colab Notebooks/notebook_clean.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"Clean notebook saved as notebook_clean.ipynb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "wAXjLwFfWre7",
        "outputId": "66781852-a0e0-4e16-80ca-6cf225852c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'content/drive/MyDrive/Colab Notebooks/Unsloth_FineTune.ipynb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4053406884.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content/drive/MyDrive/Colab Notebooks/Unsloth_FineTune.ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/drive/MyDrive/Colab Notebooks/Unsloth_FineTune.ipynb'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Tw9WckyodCzH",
        "outputId": "f735f2d2-b991-4925-81cf-e7efd420b11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "type object 'list' has no attribute 'dir'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-685389101.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'list' has no attribute 'dir'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cY4DEG8kekr0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}